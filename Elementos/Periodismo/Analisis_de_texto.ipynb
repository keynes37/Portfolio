{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Universidad del Norte\n",
        "## Maestría en Periodismo\n",
        "### Periodismo de Precisión\n",
        "#### Carlos Andrés Yanes Guerra\n",
        "\n",
        "En esta parte miraremos de forma introductoria algunos paquetes y partes de la parte de análisis de texto en **python**. Es una secuencia explicada de programación para aquellos que desean o miran a futuro la programación como elemento clave de complemento de trabajo"
      ],
      "metadata": {
        "id": "PADxTKh5f5yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos los paquetes a trabajar\n",
        "import string # Paquete de constantes\n",
        "from string import Formatter\n",
        "from string import Template\n",
        "\n",
        "# Las cadenas de código que se pueden dar en un programa\n",
        "print('Palabras comunes: ',string.ascii_letters)\n",
        "print('En minusculas: ',string.ascii_lowercase)\n",
        "print('Caso Mayusculas: ',string.ascii_uppercase)\n",
        "print('Tenemos digitos: ',string.digits)\n",
        "print('Los Hexadigitos: ',string.hexdigits)\n",
        "print('Espacios en blanco: ',string.whitespace)  # ' \\t\\n\\r\\x0b\\x0c'\n",
        "print('Cadenas de puntuación: ',string.punctuation)\n",
        "print('Todo impreso: ',string.printable)"
      ],
      "metadata": {
        "id": "ZwcbYgPujjXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora miraremos algo mas interesante"
      ],
      "metadata": {
        "id": "2ScDdmFrkZ-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplos con Formatter\n",
        "formato = Formatter()\n",
        "print(formato.format('{website}', website='Maestría en Periodismo'))\n",
        "print(formato.format('{} {website}', 'Bienvenido(a)s', website='a texto en códigos'))\n",
        "# Miremos algo similar\n",
        "print('{} {website}'.format('Bienvenido(a)s', website='a texto con café y código'))"
      ],
      "metadata": {
        "id": "xaWqXFRikhgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En algunas ocasiones es bueno mirar las estructuras de un texto. En el podemos contar palabras (mirar logicamente $E[X|Condición]=true$ de forma booleana). Mire el siguiente ejemplo a continuación:"
      ],
      "metadata": {
        "id": "TxCMvKpJtuqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Opciones de métricas livianas en los textos de análisis solo para mirar carácteres\n",
        "print('Algunas veces por ir en contravía de la vida he sentido que voy por el camino errado'.count('o'))\n",
        "print('Algunas veces por ir en contravía de la vida he sentido que voy por el camino errado'.endswith('e'))\n",
        "print('Algunas veces por ir en contravía de la vida he sentido que voy por el camino errado'.startswith('H'))\n",
        "print('Algunas veces por ir en contravía de la vida he sentido que voy por el camino errado'.find('r'))\n",
        "print('Algunas veces por ir en contravía de la vida he sentido que voy por el camino errado'.find('e'))\n",
        "print('Algunas veces por ir en contravía de la vida he sentido que voy por el camino errado'.index('u'))\n",
        "print('Algunas veces por ir en contravía de la vida he sentido que voy por el camino errado'.isalnum())\n",
        "print('987143562'.isalnum())\n",
        "print('Hola'.isalpha())"
      ],
      "metadata": {
        "id": "jMbm33X1tqEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Texto con palabras y oraciones\n",
        "Especificando esto lo empezamos a mirar con algunos condicionales, intentando encontrar palabras o elementos comunes. Aparte, vamos a vincular si encontramos cierta palabra dentro de una oración."
      ],
      "metadata": {
        "id": "deXwVsfnu7NA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "oracion = 'El profesor Yanes pertenece al área cuantitativa del Departamento de economía de Uninorte'\n",
        "print('al' in oracion)\n",
        "print('brindar' in oracion)\n"
      ],
      "metadata": {
        "id": "vHiMcEy2vQJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expresiones regulares (re)\n",
        "\n",
        "En algunos estamentos y ocasiones, podemos encontrar un sin número de expresiones que usamos en nuestros escritos y establecer tambien elementos de busqueda y porque no de etiquetas."
      ],
      "metadata": {
        "id": "hSYsR_vjv6Jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Vamos a ver las expresiones regulares\n",
        "print(bool(re.search(r'es', oracion)))\n",
        "print(bool(re.search(r'xyz', oracion)))"
      ],
      "metadata": {
        "id": "16-ooQtwwNVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tambien es posible dar como resultado una etiqueta"
      ],
      "metadata": {
        "id": "ICT7IxxQwYLd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxuc8kFXNGW6"
      },
      "outputs": [],
      "source": [
        "if re.search(r'área cuantitativa', oracion):\n",
        "    print('Misión cumplida')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos hacerlo de forma negativa. Un ejemplo de eso es:"
      ],
      "metadata": {
        "id": "3uSUsXxnylj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not re.search(r'Casa por carcel', oracion):\n",
        "    print('Nada llave por acá..')"
      ],
      "metadata": {
        "id": "cOt08WszyqxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLTK (Natural Language toolkit)\n",
        "\n",
        "Es uno de los paquetes que se suele usar para **analisis de sentimiento** y tambien calcular frecuencias de expresiones"
      ],
      "metadata": {
        "id": "R-avLlgHyzij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instalar el paquete con pip\n",
        "!pip install nltk"
      ],
      "metadata": {
        "id": "_wqkokoGzEO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego de esto, podemos entonces mirar algunas consideraciones"
      ],
      "metadata": {
        "id": "vmEt13wnzOuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "7Jnw47pVzTAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizar\n",
        "\n",
        "Para sacar jugo a los textos y al análisis de estos, se debe en muchas ocasiones hacer uso de tokens que de alguna manera dicen mas cosas que por si la expresión de un texto."
      ],
      "metadata": {
        "id": "f0HYxlxbzcJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "C4b2lK-XzsSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo\n",
        "\n",
        "texto=\"\"\"Las ciencias sociales en su día a día intentan dar respuesta a preguntas interesantes que surgen de las necesidades humanas. es así como la psicologia trabaja la parte del cerebro, la economía las relaciones\n",
        "de intercambio, las humanidades tambien hacen su parte y es así como se estudia como un todo la naturaleza del ser humano\"\"\""
      ],
      "metadata": {
        "id": "zMKj39in3Ae_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los tokens funciona de la siguiente forma:"
      ],
      "metadata": {
        "id": "ZWgnftef3rNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_en_token=sent_tokenize(texto)\n",
        "print(texto_en_token)"
      ],
      "metadata": {
        "id": "qKU2J02Q3wW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si notamos, el token comienza a darse en momentos de puntuación comas o pausas en el escrito. Ahora a continuación lo haremos por palabras (es mas importante e interesante)"
      ],
      "metadata": {
        "id": "BZz3_6su4Vuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "palabra_a_palabra=word_tokenize(texto)\n",
        "print(palabra_a_palabra)"
      ],
      "metadata": {
        "id": "jhVyOD3s5aUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación vamos a mirar una pequeña forma de la distribución de palabras."
      ],
      "metadata": {
        "id": "VXE_tufg5wfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "fdist=FreqDist(palabra_a_palabra)\n",
        "print(fdist)"
      ],
      "metadata": {
        "id": "BGWn7rMB6LJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empecemos entonces a cuantificar algo de esto y encontremos palábras comunes."
      ],
      "metadata": {
        "id": "Z5gwkOg36eZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fdist.most_common(10)"
      ],
      "metadata": {
        "id": "EPfBhbm66l3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que no tendria sentido ya que son simple conectores o lo que en otra parte llamarian (stopwords). Miremos sin embargo un grafico (nuestro primero) de palabras"
      ],
      "metadata": {
        "id": "Im1H5GGu6sqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fdist.plot(30, cumulative=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ha7bgnHy8c6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Revisión de textos\n",
        "\n",
        "Vamos a tomar un ejemplo de una base de datos que contiene reseñas en ingles de algunos sitios donde se realizan visitas y se emite una _opinión_ y una clasificación. Algunas variables que tiene la base van desde el código de revisión o cliente, fecha, calificación y en efecto su opinión"
      ],
      "metadata": {
        "id": "lGRlaKGbC_iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk # Vamos hacer uso de este paquete que se encarga de tokens\n",
        "\n",
        "# Para puntuación y palabras condicionales\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import PorterStemmer\n",
        "# Tenemos a pandas para importar las bases\n",
        "import pandas as pd\n",
        "# La parte de numpy para vectores\n",
        "import numpy  as np\n",
        "\n",
        "# Paquetes para dibujar\n",
        "import plotly\n",
        "import string"
      ],
      "metadata": {
        "id": "bgISNZOjDhvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despues de establecido el entorno de trabajo, comenzamos a inspeccionar la data de trabajo."
      ],
      "metadata": {
        "id": "icdyM3M1ECwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos los datos\n",
        "datos = pd.read_csv('/content/datosrevi.csv', nrows=6000)\n",
        "datos.head()"
      ],
      "metadata": {
        "id": "E-Yfn37mESQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya con una vista preliminar de la base podemos entonces tener o tomar en cuenta solo la parte concerniente a texto. Va ser la parte mas importante para esto."
      ],
      "metadata": {
        "id": "duFlY_08E3Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Revision = datos['text']\n",
        "Revision.head()"
      ],
      "metadata": {
        "id": "-jRacbCyFD6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el evento de que querramos solo conocer una de las tantas reseñas que se han establecido, podemos realizarlo de tal forma o manera que:"
      ],
      "metadata": {
        "id": "TM-RgS3EFT54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Revision[4230]"
      ],
      "metadata": {
        "id": "AdltcixIFfI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe que este texto contiene carácteres especiales y puede estar usando incluso emojis y otros elementos que por lo pronto no son importantes para este caso ni que aportan algo diferente."
      ],
      "metadata": {
        "id": "-P_Q_5GMFlN7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86xBTbWh9hsv"
      },
      "outputs": [],
      "source": [
        "# Para tokenizar una expresión podemos implementar:\n",
        "oraciones = nltk.sent_tokenize(Revision[0])\n",
        "for oracion in oraciones:\n",
        "    print(oracion)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que el texto es mas simple y mas amigable con la lectura o interpretación de algo que quiere mencionar cierto cliente. La parte de tokenizar tambien se puede hacer simple con elementos de palabra a palabra. Para hacer eso, podemos crear la siguiente **función**:"
      ],
      "metadata": {
        "id": "AAA8ZfOXGQFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oraciones = nltk.sent_tokenize(datos['text'][0])\n",
        "for oracion in oraciones:\n",
        "    palabras = nltk.word_tokenize(oracion)\n",
        "    print(oracion)\n",
        "    print(palabras)\n",
        "    print()"
      ],
      "metadata": {
        "id": "51mV5cXrH98r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metricas en texto\n",
        "\n",
        "Usemos entonces la parte cuantitativa de esto. Con eso podemos por lo pronto hacer un par de métricas."
      ],
      "metadata": {
        "id": "bo6U1wxXO11m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "longitud_texto = Revision.apply(lambda x: len(nltk.word_tokenize(x)))"
      ],
      "metadata": {
        "id": "7J14pYITPBWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se demora un poco... pero ya haremos magia"
      ],
      "metadata": {
        "id": "ssc1ek5kYrif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min(longitud_texto)"
      ],
      "metadata": {
        "id": "3i6u9hl4Yv3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora tamaño mayor\n",
        "max(longitud_texto)"
      ],
      "metadata": {
        "id": "I6xfQoynY0Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acá los ejemplos mas completos:"
      ],
      "metadata": {
        "id": "2FI1rGKXZCIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Revision[longitud_texto[longitud_texto == 2].index]"
      ],
      "metadata": {
        "id": "lFGEShNtYVFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Revision[longitud_texto[longitud_texto == max(longitud_texto)].index]\n",
        "print(Revision[257])"
      ],
      "metadata": {
        "id": "pbCeMEQbZWH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Algo mas gráfico\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 20, 6\n",
        "longitud_texto.hist(bins = 25)"
      ],
      "metadata": {
        "id": "iOcyULk9ZyfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hagamos algo mas claro\n",
        "\n",
        "Las nubes de palabras ayudan a encontrar cosas interesantes"
      ],
      "metadata": {
        "id": "TvIWmnMPaOOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "nube_texto = ''.join(datos.text)\n",
        "nube = WordCloud(max_font_size=100, max_words=100, background_color=\"white\",\\\n",
        "                          scale = 10,width=800, height=400).generate(nube_texto)\n",
        "plt.figure()\n",
        "plt.imshow(nube, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M70pMzypaePG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Con solo palabras buenas\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 30, 60\n",
        "\n",
        "def rating_palabras(datos,ponderacion):\n",
        "\n",
        "    filtro = datos[datos.stars == ponderacion] # Un filtro\n",
        "    Revision = filtro.text\n",
        "\n",
        "    Revision_textos = ' '.join(Revision.values) # Unir todas las palabras\n",
        "\n",
        "    # Nube\n",
        "    nube = WordCloud(max_font_size=100, max_words=100, background_color=\"white\",\\\n",
        "                          scale = 10,width=800, height=400).generate(Revision_textos)\n",
        "\n",
        "    # Grafico\n",
        "    plt.figure()\n",
        "    plt.imshow(nube, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qQ0c00d2bh7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo anterior es la programación de la función, miremos si funciona"
      ],
      "metadata": {
        "id": "Q5t1PjHDggj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_palabras(datos,5)"
      ],
      "metadata": {
        "id": "_HiFszS0gmZn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}